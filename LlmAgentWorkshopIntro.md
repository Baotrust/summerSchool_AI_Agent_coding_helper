# ğŸ§  Local AI Coding Agent â€” Workshop Primer

This document introduces the **practical steps** for building your own **local AI coding assistant**. You will create a **project-specific AI agent** that runs entirely offline, uses **local models**, and understands the **structure of your code projects**.

We focus on:

- ğŸ”§ Using local LLMs (like Mistral via `llama.cpp`)
- ğŸ“ Providing **per-project awareness** via folder summaries
- ğŸ§  Building project-level memory with SQLite
- ğŸ’» Offline operation â€” no external API dependencies

---

## ğŸš€ What Are We Building?

An **offline coding agent** that:

1. Loads a code project

2. Scans the project folder (structure + key files)

3. Builds smart prompts from history and project summaries

4. Answers your questions about your project:

   - Explains code structure
   - Suggests improvements
   - Helps write documentation
   - Discusses code logic

5. Stores prompt history in a local database (SQLite)

---

## ğŸ” What is an LLM Really Doing?

> Think of a local LLM as **a fast autocomplete with memory tricks**.

It:

- Predicts next tokens based on huge datasets
- Sees common patterns in code, comments, and file layouts
- Doesnâ€™t â€œunderstandâ€ code â€” but often **reconstructs patterns** effectively

In this workshop, youâ€™ll **guide it with project structure** and recent prompt history to make it more accurate.

---

## ğŸ” Prompt Framing (No Fine-Tuning)

| Feature       | Prompt Framing                          | Fine-Tuning                     |
| ------------- | --------------------------------------- | ------------------------------- |
| ğŸ“„ What it is | Smart instructions + context at runtime | Offline model retraining        |
| âœ… We Use?    | âœ… Yes â€” easy to modify and test        | âŒ Not covered in this workshop |
| ğŸ§  Why Useful | Adapts model to project-specific tasks  | Changes model permanently       |

---

## ğŸ“‚ Local Agent Flow

```text
Your Dev Folder
â”‚
â””â”€â”€ Project A
    â”œâ”€â”€ src/, README.md, Dockerfile
    â””â”€â”€ .git
```

1. You run the local agent

2. Agent asks: _â€œWhich project?â€_

3. Agent scans:

   - Folder structure
   - Key source/config files

4. Builds a **system prompt** using the project structure

5. Logs prompt/answer history in local SQLite DB

6. Replies to your queries about the project

---

## ğŸ§  What is a Project Summary?

> Itâ€™s a **lightweight description** of your project, generated by the AI.

Example:

```
ğŸ“ src/: main.py, utils.py
ğŸ“„ requirements.txt, Dockerfile

Summary: A Python microservice using FastAPI and Docker.
```

The agent **generates this automatically** by reading your folder contents.

---

## ğŸ› ï¸ Local Stack Overview

| Component           | Description                          |
| ------------------- | ------------------------------------ |
| `llama.cpp`         | Runs the Mistral model locally       |
| GGUF Model (Q6/Q8)  | Efficient quantized LLM              |
| Python Agent Script | Project-aware AI agent logic         |
| SQLite Database     | Stores history and project summaries |

---

## âœ… Why It Matters

- ğŸŸ¡ Works fully offline, respects project privacy
- ğŸ§  Adapts to any codebase without internet access
- ğŸ” Acts as a **context-aware coding helper**
- ğŸš€ Works on your laptop without GPU dependencies

---

## Workshop Roadmap

1. âœ… Install `llama.cpp` and Mistral GGUF model
2. âœ… Test prompt-based model responses
3. âœ… Build Python agent to select a project
4. âœ… Add automatic project summarization
5. âœ… Store project context and prompt history
6. âœ… Query the LLM with project-aware prompts

---

## ğŸ§  Final Outcome

By the end of this workshop, youâ€™ll have a:

- **Project-specific coding assistant**, offline and personal
- **Database of project memory**, reusable across sessions
- **Foundational skillset** to expand AI tools in your own codebase

---

## ğŸ“ Optional Next Steps After the Workshop

- Expand the agent with Git commit parsing
- Customize prompt strategies
- Connect to remote LLM APIs (Claude, GPT-4) for comparisons
- Explore fine-tuning options (outside this course scope)

---

## ğŸ’¡ Summary

This workshop is about **practical AI coding tools** â€” no heavy infrastructure, no cloud dependencies â€” just your machine, your code, and your own AI assistant.

---
