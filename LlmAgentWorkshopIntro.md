# 🧠 Local AI Coding Agent — Workshop Primer

This document introduces the **practical steps** for building your own **local AI coding assistant**. You will create a **project-specific AI agent** that runs entirely offline, uses **local models**, and understands the **structure of your code projects**.

We focus on:

- 🔧 Using local LLMs (like Mistral via `llama.cpp`)
- 📁 Providing **per-project awareness** via folder summaries
- 🧠 Building project-level memory with SQLite
- 💻 Offline operation — no external API dependencies

---

## 🚀 What Are We Building?

An **offline coding agent** that:

1. Loads a code project

2. Scans the project folder (structure + key files)

3. Builds smart prompts from history and project summaries

4. Answers your questions about your project:

   - Explains code structure
   - Suggests improvements
   - Helps write documentation
   - Discusses code logic

5. Stores prompt history in a local database (SQLite)

---

## 🔍 What is an LLM Really Doing?

> Think of a local LLM as **a fast autocomplete with memory tricks**.

It:

- Predicts next tokens based on huge datasets
- Sees common patterns in code, comments, and file layouts
- Doesn’t “understand” code — but often **reconstructs patterns** effectively

In this workshop, you’ll **guide it with project structure** and recent prompt history to make it more accurate.

---

## 🔁 Prompt Framing (No Fine-Tuning)

| Feature       | Prompt Framing                          | Fine-Tuning                     |
| ------------- | --------------------------------------- | ------------------------------- |
| 📄 What it is | Smart instructions + context at runtime | Offline model retraining        |
| ✅ We Use?    | ✅ Yes — easy to modify and test        | ❌ Not covered in this workshop |
| 🧠 Why Useful | Adapts model to project-specific tasks  | Changes model permanently       |

---

## 📂 Local Agent Flow

```text
Your Dev Folder
│
└── Project A
    ├── src/, README.md, Dockerfile
    └── .git
```

1. You run the local agent

2. Agent asks: _“Which project?”_

3. Agent scans:

   - Folder structure
   - Key source/config files

4. Builds a **system prompt** using the project structure

5. Logs prompt/answer history in local SQLite DB

6. Replies to your queries about the project

---

## 🧠 What is a Project Summary?

> It’s a **lightweight description** of your project, generated by the AI.

Example:

```
📁 src/: main.py, utils.py
📄 requirements.txt, Dockerfile

Summary: A Python microservice using FastAPI and Docker.
```

The agent **generates this automatically** by reading your folder contents.

---

## 🛠️ Local Stack Overview

| Component           | Description                          |
| ------------------- | ------------------------------------ |
| `llama.cpp`         | Runs the Mistral model locally       |
| GGUF Model (Q6/Q8)  | Efficient quantized LLM              |
| Python Agent Script | Project-aware AI agent logic         |
| SQLite Database     | Stores history and project summaries |

---

## ✅ Why It Matters

- 🟡 Works fully offline, respects project privacy
- 🧠 Adapts to any codebase without internet access
- 🔍 Acts as a **context-aware coding helper**
- 🚀 Works on your laptop without GPU dependencies

---

## Workshop Roadmap

1. ✅ Install `llama.cpp` and Mistral GGUF model
2. ✅ Test prompt-based model responses
3. ✅ Build Python agent to select a project
4. ✅ Add automatic project summarization
5. ✅ Store project context and prompt history
6. ✅ Query the LLM with project-aware prompts

---

## 🧠 Final Outcome

By the end of this workshop, you’ll have a:

- **Project-specific coding assistant**, offline and personal
- **Database of project memory**, reusable across sessions
- **Foundational skillset** to expand AI tools in your own codebase

---

## 📝 Optional Next Steps After the Workshop

- Expand the agent with Git commit parsing
- Customize prompt strategies
- Connect to remote LLM APIs (Claude, GPT-4) for comparisons
- Explore fine-tuning options (outside this course scope)

---

## 💡 Summary

This workshop is about **practical AI coding tools** — no heavy infrastructure, no cloud dependencies — just your machine, your code, and your own AI assistant.

---
